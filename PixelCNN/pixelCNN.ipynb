{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45960163",
      "metadata": {},
      "source": [
        "# PixelCNN Image Compression on CIFAR-10\n",
        "\n",
        "This notebook implements a PixelCNN-based learned image compression model trained on CIFAR-10.\n",
        "The model learns to predict pixel probability distributions which are then used with ANS (Asymmetric Numeral Systems) \n",
        "encoding via `pytorchac` for efficient compression.\n",
        "\n",
        "## Features:\n",
        "- Masked convolutions for autoregressive pixel prediction\n",
        "- Residual blocks for deeper architecture\n",
        "- Checkpoint saving during training\n",
        "- Comparison with traditional codecs (JPEG, PNG, WebP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f6ca9b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install torch torchvision pytorchac pillow numpy matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6125f3ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create directories for checkpoints and results\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1d05d5",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "The PixelCNN uses masked convolutions to ensure autoregressive property - each pixel only depends on previously seen pixels (raster scan order: top-to-bottom, left-to-right)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57d53ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    \"\"\"\n",
        "    Masked Convolution for autoregressive models.\n",
        "    \n",
        "    mask_type='A': First layer - excludes center pixel (for input layer)\n",
        "    mask_type='B': Subsequent layers - includes center pixel (for hidden layers)\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, **kwargs):\n",
        "        assert mask_type in ['A', 'B'], \"mask_type must be 'A' or 'B'\"\n",
        "        \n",
        "        # Ensure kernel_size is odd for symmetric masking\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        assert kernel_size[0] % 2 == 1 and kernel_size[1] % 2 == 1, \"Kernel size must be odd\"\n",
        "        \n",
        "        # Set padding to maintain spatial dimensions\n",
        "        padding = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "        super().__init__(in_channels, out_channels, kernel_size, padding=padding, **kwargs)\n",
        "        \n",
        "        self.mask_type = mask_type\n",
        "        self.register_buffer('mask', torch.ones_like(self.weight))\n",
        "        \n",
        "        # Create mask\n",
        "        _, _, h, w = self.weight.shape\n",
        "        center_h, center_w = h // 2, w // 2\n",
        "        \n",
        "        # Zero out lower half\n",
        "        self.mask[:, :, center_h + 1:, :] = 0\n",
        "        # Zero out right side of center row\n",
        "        self.mask[:, :, center_h, center_w + 1:] = 0\n",
        "        \n",
        "        # For type A, also zero out center pixel\n",
        "        if mask_type == 'A':\n",
        "            self.mask[:, :, center_h, center_w] = 0\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.weight.data *= self.mask\n",
        "        return super().forward(x)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual block with masked convolutions.\"\"\"\n",
        "    def __init__(self, channels, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = MaskedConv2d('B', channels, channels // 2, 1)\n",
        "        self.conv2 = MaskedConv2d('B', channels // 2, channels // 2, kernel_size)\n",
        "        self.conv3 = MaskedConv2d('B', channels // 2, channels, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return self.relu(out + residual)\n",
        "\n",
        "\n",
        "class PixelCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    PixelCNN for image compression.\n",
        "    \n",
        "    Predicts probability distribution over 256 pixel values for each pixel\n",
        "    conditioned on previously seen pixels.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, hidden_channels=128, num_residual_blocks=12, \n",
        "                 num_classes=256, kernel_size=7):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Initial convolution (mask type A - excludes center)\n",
        "        self.input_conv = MaskedConv2d('A', in_channels, hidden_channels, kernel_size)\n",
        "        \n",
        "        # Residual blocks\n",
        "        self.residual_blocks = nn.ModuleList([\n",
        "            ResidualBlock(hidden_channels, kernel_size=3) \n",
        "            for _ in range(num_residual_blocks)\n",
        "        ])\n",
        "        \n",
        "        # Output layers\n",
        "        self.output_conv1 = MaskedConv2d('B', hidden_channels, hidden_channels, 1)\n",
        "        self.output_conv2 = MaskedConv2d('B', hidden_channels, hidden_channels, 1)\n",
        "        \n",
        "        # Final layer outputs logits for each pixel value (0-255) for each channel\n",
        "        self.final_conv = MaskedConv2d('B', hidden_channels, in_channels * num_classes, 1)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.in_channels = in_channels\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        \n",
        "        Args:\n",
        "            x: Input image tensor of shape (B, C, H, W) with values in [0, 255] as long tensor\n",
        "               or normalized values\n",
        "        \n",
        "        Returns:\n",
        "            logits: Shape (B, C, num_classes, H, W) - logits for each pixel value\n",
        "        \"\"\"\n",
        "        # Normalize input to [-1, 1] for better training\n",
        "        if x.dtype == torch.long:\n",
        "            x = x.float() / 127.5 - 1\n",
        "        \n",
        "        out = self.relu(self.input_conv(x))\n",
        "        \n",
        "        for block in self.residual_blocks:\n",
        "            out = block(out)\n",
        "        \n",
        "        out = self.relu(self.output_conv1(out))\n",
        "        out = self.relu(self.output_conv2(out))\n",
        "        out = self.final_conv(out)\n",
        "        \n",
        "        # Reshape to (B, C, num_classes, H, W)\n",
        "        B, _, H, W = out.shape\n",
        "        out = out.view(B, self.in_channels, self.num_classes, H, W)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def get_probabilities(self, x):\n",
        "        \"\"\"Get probability distributions for each pixel.\"\"\"\n",
        "        logits = self.forward(x)\n",
        "        return F.softmax(logits, dim=2)\n",
        "    \n",
        "    def loss(self, x, target):\n",
        "        \"\"\"\n",
        "        Compute cross-entropy loss.\n",
        "        \n",
        "        Args:\n",
        "            x: Input images (B, C, H, W)\n",
        "            target: Target pixel values as long tensor (B, C, H, W) with values 0-255\n",
        "        \n",
        "        Returns:\n",
        "            loss: Cross-entropy loss (bits per sub-pixel)\n",
        "        \"\"\"\n",
        "        logits = self.forward(x)  # (B, C, num_classes, H, W)\n",
        "        B, C, num_classes, H, W = logits.shape\n",
        "        \n",
        "        # Reshape for cross entropy\n",
        "        logits = logits.permute(0, 1, 3, 4, 2).contiguous()  # (B, C, H, W, num_classes)\n",
        "        logits = logits.view(-1, num_classes)  # (B*C*H*W, num_classes)\n",
        "        target = target.view(-1)  # (B*C*H*W,)\n",
        "        \n",
        "        # Cross entropy loss in nats, convert to bits\n",
        "        loss = F.cross_entropy(logits, target, reduction='mean')\n",
        "        bits_per_subpixel = loss / np.log(2)\n",
        "        \n",
        "        return bits_per_subpixel\n",
        "\n",
        "\n",
        "# Test model instantiation\n",
        "model = PixelCNN(in_channels=3, hidden_channels=128, num_residual_blocks=12).to(device)\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "858257bf",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n",
        "Load CIFAR-10 dataset and create train/validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db65666a",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CIFAR10Compression(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    CIFAR-10 dataset wrapper for compression task.\n",
        "    Returns images as uint8 tensors (0-255).\n",
        "    \"\"\"\n",
        "    def __init__(self, root='./data', train=True, download=True):\n",
        "        # Load without normalization - we need raw pixel values\n",
        "        self.dataset = torchvision.datasets.CIFAR10(\n",
        "            root=root, \n",
        "            train=train, \n",
        "            download=download,\n",
        "            transform=transforms.ToTensor()  # Converts to [0, 1] float\n",
        "        )\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img, _ = self.dataset[idx]  # We don't need labels\n",
        "        # Convert to [0, 255] uint8 for compression\n",
        "        img_uint8 = (img * 255).to(torch.uint8)\n",
        "        return img_uint8\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "full_train_dataset = CIFAR10Compression(train=True, download=True)\n",
        "test_dataset = CIFAR10Compression(train=False, download=True)\n",
        "\n",
        "# Split training into train and validation (90/10)\n",
        "train_size = int(0.9 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_train_dataset, \n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Create dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
        "                          num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         num_workers=2, pin_memory=True)\n",
        "\n",
        "# Visualize some samples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "sample_batch = next(iter(train_loader))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = sample_batch[i].permute(1, 2, 0).numpy()\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "plt.suptitle('Sample CIFAR-10 Images')\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/sample_images.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23870bc2",
      "metadata": {},
      "source": [
        "## Training\n",
        "\n",
        "Train the PixelCNN model with checkpoint saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f1042e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CheckpointManager:\n",
        "    \"\"\"Manages model checkpoints during training.\"\"\"\n",
        "    \n",
        "    def __init__(self, checkpoint_dir='checkpoints', model_name='pixelcnn'):\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "        self.model_name = model_name\n",
        "        self.best_loss = float('inf')\n",
        "    \n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, train_loss, val_loss, is_best=False):\n",
        "        \"\"\"Save a training checkpoint.\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "        }\n",
        "        \n",
        "        # Save latest checkpoint\n",
        "        latest_path = self.checkpoint_dir / f'{self.model_name}_latest.pt'\n",
        "        torch.save(checkpoint, latest_path)\n",
        "        \n",
        "        # Save epoch checkpoint (every 5 epochs)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            epoch_path = self.checkpoint_dir / f'{self.model_name}_epoch_{epoch+1}.pt'\n",
        "            torch.save(checkpoint, epoch_path)\n",
        "            print(f\"  Saved epoch checkpoint: {epoch_path}\")\n",
        "        \n",
        "        # Save best model\n",
        "        if is_best:\n",
        "            best_path = self.checkpoint_dir / f'{self.model_name}_best.pt'\n",
        "            torch.save(checkpoint, best_path)\n",
        "            print(f\"  Saved best model: {best_path}\")\n",
        "    \n",
        "    def load_checkpoint(self, model, optimizer=None, scheduler=None, checkpoint_path=None):\n",
        "        \"\"\"Load a checkpoint.\"\"\"\n",
        "        if checkpoint_path is None:\n",
        "            checkpoint_path = self.checkpoint_dir / f'{self.model_name}_latest.pt'\n",
        "        \n",
        "        if not checkpoint_path.exists():\n",
        "            print(\"No checkpoint found, starting from scratch\")\n",
        "            return 0\n",
        "        \n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        \n",
        "        if optimizer and 'optimizer_state_dict' in checkpoint:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        \n",
        "        if scheduler and checkpoint.get('scheduler_state_dict'):\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        \n",
        "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']+1}\")\n",
        "        print(f\"  Train loss: {checkpoint['train_loss']:.4f} bpp\")\n",
        "        print(f\"  Val loss: {checkpoint['val_loss']:.4f} bpp\")\n",
        "        \n",
        "        return checkpoint['epoch'] + 1\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
        "    for batch in pbar:\n",
        "        batch = batch.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Input is the image, target is the same image (autoregressive prediction)\n",
        "        input_img = batch.float() / 127.5 - 1  # Normalize to [-1, 1]\n",
        "        target = batch.long()  # Target as class indices (0-255)\n",
        "        \n",
        "        loss = model.loss(input_img, target)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f} bpp'})\n",
        "    \n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, val_loader, device):\n",
        "    \"\"\"Validate the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    for batch in tqdm(val_loader, desc='Validating', leave=False):\n",
        "        batch = batch.to(device)\n",
        "        \n",
        "        input_img = batch.float() / 127.5 - 1\n",
        "        target = batch.long()\n",
        "        \n",
        "        loss = model.loss(input_img, target)\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=50, lr=3e-4, resume=True):\n",
        "    \"\"\"Full training loop with checkpointing.\"\"\"\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "    \n",
        "    checkpoint_manager = CheckpointManager()\n",
        "    \n",
        "    # Resume from checkpoint if exists\n",
        "    start_epoch = 0\n",
        "    if resume:\n",
        "        start_epoch = checkpoint_manager.load_checkpoint(model, optimizer, scheduler)\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    print(f\"\\nStarting training from epoch {start_epoch + 1}\")\n",
        "    print(f\"Total epochs: {num_epochs}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        \n",
        "        # Train\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss = validate(model, val_loader, device)\n",
        "        val_losses.append(val_loss)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        # Check if best model\n",
        "        is_best = val_loss < best_val_loss\n",
        "        if is_best:\n",
        "            best_val_loss = val_loss\n",
        "        \n",
        "        print(f\"  Train Loss: {train_loss:.4f} bpp | Val Loss: {val_loss:.4f} bpp\")\n",
        "        print(f\"  Best Val Loss: {best_val_loss:.4f} bpp\")\n",
        "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "        \n",
        "        # Save checkpoint\n",
        "        checkpoint_manager.save_checkpoint(\n",
        "            model, optimizer, scheduler, epoch, train_loss, val_loss, is_best\n",
        "        )\n",
        "    \n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss (bits per sub-pixel)')\n",
        "    plt.title('Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('results/training_curve.png', dpi=150)\n",
        "    plt.show()\n",
        "    \n",
        "    # Save training history\n",
        "    history = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'best_val_loss': best_val_loss\n",
        "    }\n",
        "    with open('results/training_history.json', 'w') as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "    \n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f066530",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "NUM_EPOCHS = 50  # Adjust based on your compute budget\n",
        "LEARNING_RATE = 3e-4\n",
        "\n",
        "# Initialize fresh model or use existing one\n",
        "model = PixelCNN(\n",
        "    in_channels=3, \n",
        "    hidden_channels=128, \n",
        "    num_residual_blocks=12\n",
        ").to(device)\n",
        "\n",
        "# Train the model\n",
        "train_losses, val_losses = train_model(\n",
        "    model, \n",
        "    train_loader, \n",
        "    val_loader, \n",
        "    num_epochs=NUM_EPOCHS, \n",
        "    lr=LEARNING_RATE,\n",
        "    resume=True  # Set to False to start fresh\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc0290b",
      "metadata": {},
      "source": [
        "## Compression with ANS Encoding\n",
        "\n",
        "Use pytorchac for Asymmetric Numeral Systems (ANS) entropy coding.\n",
        "The PixelCNN provides probability distributions, and ANS encodes symbols based on these distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3128b703",
      "metadata": {},
      "outputs": [],
      "source": [
        "import constriction\n",
        "\n",
        "class PixelCNNCompressor:\n",
        "    \"\"\"Compress images using PixelCNN + ANS encoding (constriction library).\"\"\"\n",
        "    \n",
        "    def __init__(self, model, device='cuda'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.eval()\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def compress(self, image):\n",
        "        \"\"\"Compress a single image using ANS encoding with constriction.\"\"\"\n",
        "        self.model.eval()\n",
        "        C, H, W = image.shape\n",
        "        image = image.to(self.device)\n",
        "        \n",
        "        input_img = image.float().unsqueeze(0) / 127.5 - 1\n",
        "        logits = self.model(input_img)\n",
        "        probs = F.softmax(logits, dim=2).squeeze(0)\n",
        "        \n",
        "        # Shape: (C, 256, H, W) -> (C*H*W, 256)\n",
        "        probs = probs.permute(0, 2, 3, 1).contiguous().view(-1, 256)\n",
        "        symbols = image.view(-1).to(torch.int32).cpu().numpy()\n",
        "        \n",
        "        # Normalize probabilities and convert to numpy\n",
        "        probs = probs.clamp(min=1e-9)\n",
        "        probs = probs / probs.sum(dim=-1, keepdim=True)\n",
        "        probs_np = probs.cpu().numpy().astype(np.float32)\n",
        "        \n",
        "        # Use constriction's ANS encoder\n",
        "        ans = constriction.stream.stack.AnsCoder()\n",
        "        model_family = constriction.stream.model.Categorical(perfect=False)\n",
        "        ans.encode_reverse(symbols, model_family, probs_np)\n",
        "        \n",
        "        compressed = ans.get_compressed()\n",
        "        return compressed.tobytes(), (C, H, W)\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def decompress(self, compressed_bytes, shape):\n",
        "        \"\"\"Decompress an image using PixelCNN + ANS.\"\"\"\n",
        "        self.model.eval()\n",
        "        C, H, W = shape\n",
        "        \n",
        "        # Get probabilities from zeros (due to autoregressive masking)\n",
        "        image = torch.zeros(1, C, H, W, device=self.device)\n",
        "        input_img = image / 127.5 - 1\n",
        "        logits = self.model(input_img)\n",
        "        probs = F.softmax(logits, dim=2).squeeze(0)\n",
        "        probs = probs.permute(0, 2, 3, 1).contiguous().view(-1, 256)\n",
        "        \n",
        "        probs = probs.clamp(min=1e-9)\n",
        "        probs = probs / probs.sum(dim=-1, keepdim=True)\n",
        "        probs_np = probs.cpu().numpy().astype(np.float32)\n",
        "        \n",
        "        # Decode using constriction\n",
        "        compressed = np.frombuffer(compressed_bytes, dtype=np.uint32)\n",
        "        ans = constriction.stream.stack.AnsCoder(compressed)\n",
        "        model_family = constriction.stream.model.Categorical(perfect=False)\n",
        "        decoded = ans.decode(model_family, probs_np)\n",
        "        \n",
        "        return torch.from_numpy(decoded.astype(np.float32)).view(C, H, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470d4a52",
      "metadata": {},
      "source": [
        "## Evaluation: Compare with Traditional Codecs\n",
        "\n",
        "Compare PixelCNN compression with PNG (lossless), JPEG (lossy), and WebP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb8a3ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TraditionalCodec:\n",
        "    \"\"\"Wrapper for traditional image codecs.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def compress_png(image_np):\n",
        "        \"\"\"Compress using PNG (lossless).\"\"\"\n",
        "        img = Image.fromarray(image_np)\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format='PNG', optimize=True)\n",
        "        return buffer.getvalue()\n",
        "    \n",
        "    @staticmethod\n",
        "    def compress_jpeg(image_np, quality=95):\n",
        "        \"\"\"Compress using JPEG.\"\"\"\n",
        "        img = Image.fromarray(image_np)\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format='JPEG', quality=quality)\n",
        "        return buffer.getvalue()\n",
        "    \n",
        "    @staticmethod\n",
        "    def decompress_jpeg(compressed_bytes):\n",
        "        \"\"\"Decompress JPEG.\"\"\"\n",
        "        buffer = io.BytesIO(compressed_bytes)\n",
        "        img = Image.open(buffer)\n",
        "        return np.array(img)\n",
        "    \n",
        "    @staticmethod\n",
        "    def compress_webp(image_np, quality=100, lossless=True):\n",
        "        \"\"\"Compress using WebP.\"\"\"\n",
        "        img = Image.fromarray(image_np)\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format='WEBP', quality=quality, lossless=lossless)\n",
        "        return buffer.getvalue()\n",
        "    \n",
        "    @staticmethod\n",
        "    def decompress_webp(compressed_bytes):\n",
        "        \"\"\"Decompress WebP.\"\"\"\n",
        "        buffer = io.BytesIO(compressed_bytes)\n",
        "        img = Image.open(buffer)\n",
        "        return np.array(img)\n",
        "\n",
        "\n",
        "def compute_metrics(original, reconstructed):\n",
        "    \"\"\"Compute image quality metrics.\"\"\"\n",
        "    original = original.astype(np.float64)\n",
        "    reconstructed = reconstructed.astype(np.float64)\n",
        "    \n",
        "    mse = np.mean((original - reconstructed) ** 2)\n",
        "    \n",
        "    if mse == 0:\n",
        "        psnr = float('inf')\n",
        "    else:\n",
        "        psnr = 10 * np.log10((255 ** 2) / mse)\n",
        "    \n",
        "    return {'mse': mse, 'psnr': psnr}\n",
        "\n",
        "\n",
        "def compute_bpp(compressed_size_bytes, image_shape):\n",
        "    \"\"\"Compute bits per pixel.\"\"\"\n",
        "    _, h, w = image_shape\n",
        "    total_pixels = h * w\n",
        "    total_bits = compressed_size_bytes * 8\n",
        "    return total_bits / total_pixels\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_compression(model, val_loader, num_samples=100, device='cuda'):\n",
        "    \"\"\"\n",
        "    Evaluate compression performance on validation set.\n",
        "    Compare PixelCNN with traditional codecs.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    compressor = PixelCNNCompressor(model, device)\n",
        "    codec = TraditionalCodec()\n",
        "    \n",
        "    results = {\n",
        "        'pixelcnn': {'bpp': [], 'psnr': []},\n",
        "        'png': {'bpp': [], 'psnr': []},\n",
        "        'jpeg_95': {'bpp': [], 'psnr': []},\n",
        "        'jpeg_75': {'bpp': [], 'psnr': []},\n",
        "        'webp_lossless': {'bpp': [], 'psnr': []},\n",
        "        'webp_lossy': {'bpp': [], 'psnr': []},\n",
        "    }\n",
        "    \n",
        "    sample_count = 0\n",
        "    \n",
        "    print(f\"Evaluating on {num_samples} samples...\")\n",
        "    \n",
        "    for batch in tqdm(val_loader, desc='Evaluating'):\n",
        "        for img_tensor in batch:\n",
        "            if sample_count >= num_samples:\n",
        "                break\n",
        "            \n",
        "            img_np = img_tensor.permute(1, 2, 0).numpy()  # (H, W, C)\n",
        "            \n",
        "            # PixelCNN compression (using fast parallel method)\n",
        "            try:\n",
        "                compressed_pixelcnn, shape = compressor.compress(img_tensor)\n",
        "                pixelcnn_bpp = compute_bpp(len(compressed_pixelcnn), img_tensor.shape)\n",
        "                results['pixelcnn']['bpp'].append(pixelcnn_bpp)\n",
        "                results['pixelcnn']['psnr'].append(float('inf'))  # Lossless\n",
        "            except Exception as e:\n",
        "                print(f\"PixelCNN compression error: {e}\")\n",
        "                results['pixelcnn']['bpp'].append(float('nan'))\n",
        "                results['pixelcnn']['psnr'].append(float('nan'))\n",
        "            \n",
        "            # PNG (lossless)\n",
        "            compressed_png = codec.compress_png(img_np)\n",
        "            png_bpp = compute_bpp(len(compressed_png), img_tensor.shape)\n",
        "            results['png']['bpp'].append(png_bpp)\n",
        "            results['png']['psnr'].append(float('inf'))\n",
        "            \n",
        "            # JPEG quality 95\n",
        "            compressed_jpeg95 = codec.compress_jpeg(img_np, quality=95)\n",
        "            jpeg95_bpp = compute_bpp(len(compressed_jpeg95), img_tensor.shape)\n",
        "            decoded_jpeg95 = codec.decompress_jpeg(compressed_jpeg95)\n",
        "            jpeg95_metrics = compute_metrics(img_np, decoded_jpeg95)\n",
        "            results['jpeg_95']['bpp'].append(jpeg95_bpp)\n",
        "            results['jpeg_95']['psnr'].append(jpeg95_metrics['psnr'])\n",
        "            \n",
        "            # JPEG quality 75\n",
        "            compressed_jpeg75 = codec.compress_jpeg(img_np, quality=75)\n",
        "            jpeg75_bpp = compute_bpp(len(compressed_jpeg75), img_tensor.shape)\n",
        "            decoded_jpeg75 = codec.decompress_jpeg(compressed_jpeg75)\n",
        "            jpeg75_metrics = compute_metrics(img_np, decoded_jpeg75)\n",
        "            results['jpeg_75']['bpp'].append(jpeg75_bpp)\n",
        "            results['jpeg_75']['psnr'].append(jpeg75_metrics['psnr'])\n",
        "            \n",
        "            # WebP lossless\n",
        "            compressed_webp_ll = codec.compress_webp(img_np, lossless=True)\n",
        "            webp_ll_bpp = compute_bpp(len(compressed_webp_ll), img_tensor.shape)\n",
        "            results['webp_lossless']['bpp'].append(webp_ll_bpp)\n",
        "            results['webp_lossless']['psnr'].append(float('inf'))\n",
        "            \n",
        "            # WebP lossy quality 95\n",
        "            compressed_webp_lossy = codec.compress_webp(img_np, quality=95, lossless=False)\n",
        "            webp_lossy_bpp = compute_bpp(len(compressed_webp_lossy), img_tensor.shape)\n",
        "            decoded_webp = codec.decompress_webp(compressed_webp_lossy)\n",
        "            webp_metrics = compute_metrics(img_np, decoded_webp)\n",
        "            results['webp_lossy']['bpp'].append(webp_lossy_bpp)\n",
        "            results['webp_lossy']['psnr'].append(webp_metrics['psnr'])\n",
        "            \n",
        "            sample_count += 1\n",
        "        \n",
        "        if sample_count >= num_samples:\n",
        "            break\n",
        "    \n",
        "    # Compute averages\n",
        "    summary = {}\n",
        "    for codec_name, metrics in results.items():\n",
        "        valid_bpp = [b for b in metrics['bpp'] if not np.isnan(b)]\n",
        "        valid_psnr = [p for p in metrics['psnr'] if not np.isnan(p) and not np.isinf(p)]\n",
        "        \n",
        "        summary[codec_name] = {\n",
        "            'avg_bpp': np.mean(valid_bpp) if valid_bpp else float('nan'),\n",
        "            'std_bpp': np.std(valid_bpp) if valid_bpp else float('nan'),\n",
        "            'avg_psnr': np.mean(valid_psnr) if valid_psnr else 'lossless',\n",
        "            'num_samples': len(valid_bpp)\n",
        "        }\n",
        "    \n",
        "    return results, summary\n",
        "\n",
        "\n",
        "def print_results_table(summary):\n",
        "    \"\"\"Print a formatted results table.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"COMPRESSION COMPARISON RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"{'Codec':<20} {'Avg BPP':<15} {'Std BPP':<15} {'Avg PSNR (dB)':<15}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    for codec_name, stats in summary.items():\n",
        "        psnr_str = f\"{stats['avg_psnr']:.2f}\" if isinstance(stats['avg_psnr'], float) else stats['avg_psnr']\n",
        "        print(f\"{codec_name:<20} {stats['avg_bpp']:<15.4f} {stats['std_bpp']:<15.4f} {psnr_str:<15}\")\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "def plot_results(results, summary):\n",
        "    \"\"\"Plot comparison results.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # BPP comparison\n",
        "    codecs = list(summary.keys())\n",
        "    bpps = [summary[c]['avg_bpp'] for c in codecs]\n",
        "    stds = [summary[c]['std_bpp'] for c in codecs]\n",
        "    \n",
        "    colors = ['#2ecc71', '#3498db', '#e74c3c', '#e67e22', '#9b59b6', '#1abc9c']\n",
        "    \n",
        "    bars = axes[0].bar(codecs, bpps, yerr=stds, capsize=5, color=colors)\n",
        "    axes[0].set_ylabel('Bits Per Pixel (BPP)')\n",
        "    axes[0].set_title('Compression Ratio Comparison')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, bpp in zip(bars, bpps):\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                     f'{bpp:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # BPP distribution (box plot)\n",
        "    bpp_data = [results[c]['bpp'] for c in codecs]\n",
        "    bp = axes[1].boxplot(bpp_data, labels=codecs, patch_artist=True)\n",
        "    for patch, color in zip(bp['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "    axes[1].set_ylabel('Bits Per Pixel (BPP)')\n",
        "    axes[1].set_title('BPP Distribution')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/compression_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef8fe6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model for evaluation\n",
        "checkpoint_path = Path('checkpoints/pixelcnn_best.pt')\n",
        "\n",
        "if checkpoint_path.exists():\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "    print(f\"Validation loss: {checkpoint['val_loss']:.4f} bpp\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Using current model state.\")\n",
        "    print(\"Make sure to train the model first!\")\n",
        "\n",
        "# Run evaluation\n",
        "results, summary = evaluate_compression(model, val_loader, num_samples=100, device=device)\n",
        "\n",
        "# Print results\n",
        "print_results_table(summary)\n",
        "\n",
        "# Plot results\n",
        "plot_results(results, summary)\n",
        "\n",
        "# Save results\n",
        "with open('results/compression_results.json', 'w') as f:\n",
        "    # Convert numpy to python types for JSON serialization\n",
        "    json_results = {}\n",
        "    for codec, metrics in summary.items():\n",
        "        json_results[codec] = {\n",
        "            'avg_bpp': float(metrics['avg_bpp']) if not np.isnan(metrics['avg_bpp']) else None,\n",
        "            'std_bpp': float(metrics['std_bpp']) if not np.isnan(metrics['std_bpp']) else None,\n",
        "            'avg_psnr': float(metrics['avg_psnr']) if isinstance(metrics['avg_psnr'], float) else metrics['avg_psnr'],\n",
        "            'num_samples': metrics['num_samples']\n",
        "        }\n",
        "    json.dump(json_results, f, indent=2)\n",
        "print(\"\\nResults saved to results/compression_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf93bda",
      "metadata": {},
      "source": [
        "## Visualize Compression on Individual Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518aaa21",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def visualize_compression_example(model, val_loader, device='cuda', num_examples=3):\n",
        "    \"\"\"Visualize compression on individual images.\"\"\"\n",
        "    model.eval()\n",
        "    compressor = PixelCNNCompressor(model, device)\n",
        "    codec = TraditionalCodec()\n",
        "    \n",
        "    # Get some samples\n",
        "    samples = next(iter(val_loader))[:num_examples]\n",
        "    \n",
        "    fig, axes = plt.subplots(num_examples, 5, figsize=(15, 3*num_examples))\n",
        "    if num_examples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for idx, img_tensor in enumerate(samples):\n",
        "        img_np = img_tensor.permute(1, 2, 0).numpy()\n",
        "        \n",
        "        # Compute compressed sizes\n",
        "        try:\n",
        "            compressed_pixelcnn, _ = compressor.compress(img_tensor)\n",
        "            pixelcnn_size = len(compressed_pixelcnn)\n",
        "        except:\n",
        "            pixelcnn_size = -1\n",
        "        \n",
        "        compressed_png = codec.compress_png(img_np)\n",
        "        compressed_jpeg = codec.compress_jpeg(img_np, quality=75)\n",
        "        compressed_webp = codec.compress_webp(img_np, lossless=True)\n",
        "        \n",
        "        # Decode JPEG for visualization\n",
        "        decoded_jpeg = codec.decompress_jpeg(compressed_jpeg)\n",
        "        \n",
        "        # Original size (uncompressed)\n",
        "        original_size = img_np.size  # H * W * C bytes\n",
        "        \n",
        "        # Plot\n",
        "        axes[idx, 0].imshow(img_np)\n",
        "        axes[idx, 0].set_title(f'Original\\n{original_size} bytes')\n",
        "        axes[idx, 0].axis('off')\n",
        "        \n",
        "        axes[idx, 1].imshow(img_np)\n",
        "        pixelcnn_str = f'{pixelcnn_size}' if pixelcnn_size > 0 else 'N/A'\n",
        "        axes[idx, 1].set_title(f'PixelCNN+ANS\\n{pixelcnn_str} bytes')\n",
        "        axes[idx, 1].axis('off')\n",
        "        \n",
        "        axes[idx, 2].imshow(img_np)\n",
        "        axes[idx, 2].set_title(f'PNG\\n{len(compressed_png)} bytes')\n",
        "        axes[idx, 2].axis('off')\n",
        "        \n",
        "        axes[idx, 3].imshow(decoded_jpeg)\n",
        "        axes[idx, 3].set_title(f'JPEG (Q=75)\\n{len(compressed_jpeg)} bytes')\n",
        "        axes[idx, 3].axis('off')\n",
        "        \n",
        "        axes[idx, 4].imshow(img_np)\n",
        "        axes[idx, 4].set_title(f'WebP Lossless\\n{len(compressed_webp)} bytes')\n",
        "        axes[idx, 4].axis('off')\n",
        "    \n",
        "    plt.suptitle('Compression Comparison (Byte Sizes)', fontsize=14, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/compression_examples.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize examples\n",
        "visualize_compression_example(model, val_loader, device=device, num_examples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a202067",
      "metadata": {},
      "source": [
        "## Theoretical Analysis\n",
        "\n",
        "Compute the theoretical compression rate based on model's cross-entropy loss (which equals the entropy of the predicted distribution when optimally coded)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd88319",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_theoretical_bpp(model, data_loader, device='cuda', num_batches=50):\n",
        "    \"\"\"\n",
        "    Compute the theoretical bits-per-pixel based on model's predictions.\n",
        "    \n",
        "    The cross-entropy loss in bits is equivalent to the expected codelength\n",
        "    under optimal entropy coding (Shannon's source coding theorem).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    total_bits = 0\n",
        "    total_subpixels = 0\n",
        "    \n",
        "    for i, batch in enumerate(tqdm(data_loader, desc='Computing theoretical BPP')):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "            \n",
        "        batch = batch.to(device)\n",
        "        B, C, H, W = batch.shape\n",
        "        \n",
        "        input_img = batch.float() / 127.5 - 1\n",
        "        target = batch.long()\n",
        "        \n",
        "        # Get bits per sub-pixel\n",
        "        loss_bpp = model.loss(input_img, target)\n",
        "        \n",
        "        # Total bits for this batch\n",
        "        num_subpixels = B * C * H * W\n",
        "        total_bits += loss_bpp.item() * num_subpixels\n",
        "        total_subpixels += num_subpixels\n",
        "    \n",
        "    # Bits per sub-pixel (per channel)\n",
        "    bpp_subpixel = total_bits / total_subpixels\n",
        "    \n",
        "    # Bits per pixel (all channels combined) - for CIFAR-10: 3 channels\n",
        "    bpp_pixel = bpp_subpixel * 3\n",
        "    \n",
        "    return bpp_subpixel, bpp_pixel\n",
        "\n",
        "\n",
        "# Compute theoretical BPP\n",
        "bpp_subpixel, bpp_pixel = compute_theoretical_bpp(model, val_loader, device=device)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"THEORETICAL COMPRESSION RATE (based on model loss)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Bits per sub-pixel (channel): {bpp_subpixel:.4f}\")\n",
        "print(f\"Bits per pixel (RGB):         {bpp_pixel:.4f}\")\n",
        "print(f\"Theoretical file size for 32x32 RGB image:\")\n",
        "print(f\"  - Uncompressed: {32*32*3*8} bits ({32*32*3} bytes)\")\n",
        "print(f\"  - PixelCNN:     {bpp_pixel * 32 * 32:.0f} bits ({bpp_pixel * 32 * 32 / 8:.0f} bytes)\")\n",
        "print(f\"Compression ratio: {(32*32*3*8) / (bpp_pixel * 32 * 32):.2f}x\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80273b40",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Files Created:\n",
        "- `pixelCNN.ipynb` - This notebook with full training and evaluation pipeline\n",
        "- `evaluate_compression.py` - Standalone script for detailed evaluation\n",
        "- `checkpoints/` - Directory containing model checkpoints\n",
        "- `results/` - Directory containing evaluation results and plots\n",
        "\n",
        "### Usage:\n",
        "\n",
        "1. **Training**: Run the training cells above. Checkpoints are saved automatically.\n",
        "\n",
        "2. **Evaluation in notebook**: Run the evaluation cells to compare with traditional codecs.\n",
        "\n",
        "3. **Standalone evaluation**:\n",
        "```bash\n",
        "python evaluate_compression.py --checkpoint checkpoints/pixelcnn_best.pt --num_samples 500\n",
        "```\n",
        "\n",
        "### Expected Results:\n",
        "\n",
        "After training for ~50 epochs, the PixelCNN should achieve approximately:\n",
        "- **4-5 bits per pixel (bpp)** on CIFAR-10\n",
        "\n",
        "Comparison with traditional lossless codecs on CIFAR-10:\n",
        "- **PNG**: ~6-7 bpp\n",
        "- **WebP Lossless**: ~5-6 bpp\n",
        "\n",
        "The learned compression model can potentially achieve better rates by exploiting the statistical regularities learned from the training data."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
