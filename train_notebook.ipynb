{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b07a25a",
   "metadata": {},
   "source": [
    "# ðŸ—œï¸ Integer Discrete Flow (IDF) Training\n",
    "\n",
    "Train a lossless image compression model using normalizing flows on ImageNet-1k crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local imports\n",
    "from src.model import IntegerDiscreteFlow, create_idf_model\n",
    "from src.dataset.crop_dataset import CropDataStream\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabae82",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    # Model architecture\n",
    "    \"in_channels\": 3,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"num_levels\": 3,\n",
    "    \"num_steps\": 8,\n",
    "    \n",
    "    # Training\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"total_steps\": 50000,\n",
    "    \n",
    "    # Data\n",
    "    \"crop_size\": 64,\n",
    "    \"dataset_name\": \"ILSVRC/imagenet-1k\",\n",
    "    \n",
    "    # Logging & Checkpointing\n",
    "    \"log_interval\": 100,\n",
    "    \"val_interval\": 1000,\n",
    "    \"save_interval\": 5000,\n",
    "    \"checkpoint_dir\": \"checkpoints\",\n",
    "    \n",
    "    # Hardware\n",
    "    \"use_amp\": True,  # Automatic mixed precision\n",
    "}\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702249e",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Initialize the Integer Discrete Flow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model_config = {\n",
    "    \"in_channels\": config[\"in_channels\"],\n",
    "    \"hidden_channels\": config[\"hidden_channels\"],\n",
    "    \"num_levels\": config[\"num_levels\"],\n",
    "    \"num_steps\": config[\"num_steps\"],\n",
    "}\n",
    "\n",
    "model = create_idf_model(model_config).to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model config: {model_config}\")\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12b5c0",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Create streaming dataloaders using `CropDataStream` for ImageNet-1k random crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Stack crops and scale to [0, 255] integer range.\"\"\"\n",
    "    crops = torch.stack(batch)\n",
    "    # Convert from [0, 1] float to [0, 255] for the IDF model\n",
    "    crops = (crops * 255.0).clamp(0, 255)\n",
    "    return crops\n",
    "\n",
    "# Create training dataset and dataloader\n",
    "train_dataset = CropDataStream(\n",
    "    split=\"train\",\n",
    "    crop_size=config[\"crop_size\"],\n",
    "    dataset_name=config[\"dataset_name\"],\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,  # Streaming dataset works best with 0 workers\n",
    "    pin_memory=True if device.type == \"cuda\" else False,\n",
    ")\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "val_dataset = CropDataStream(\n",
    "    split=\"validation\",\n",
    "    crop_size=config[\"crop_size\"],\n",
    "    dataset_name=config[\"dataset_name\"],\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == \"cuda\" else False,\n",
    ")\n",
    "\n",
    "print(\"âœ“ Data loaders created\")\n",
    "print(f\"  - Crop size: {config['crop_size']}x{config['crop_size']}\")\n",
    "print(f\"  - Batch size: {config['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4876193",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Configure optimizer, scheduler, and training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config[\"learning_rate\"],\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "# Learning rate scheduler (Cosine Annealing with Warm Restarts)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10000,  # Restart period\n",
    "    T_mult=2,   # Period multiplier after each restart\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "use_amp = config[\"use_amp\"] and device.type == \"cuda\"\n",
    "scaler = GradScaler(\"cuda\") if use_amp else None\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = Path(config[\"checkpoint_dir\"])\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training state\n",
    "global_step = 0\n",
    "best_bpd = float(\"inf\")\n",
    "train_history = []\n",
    "\n",
    "print(f\"âœ“ Training setup complete\")\n",
    "print(f\"  - Learning rate: {config['learning_rate']}\")\n",
    "print(f\"  - Mixed precision: {use_amp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    \"\"\"Perform a single training step with NaN detection.\"\"\"\n",
    "    global global_step\n",
    "    \n",
    "    model.train()\n",
    "    batch = batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if use_amp:\n",
    "        with autocast(\"cuda\"):\n",
    "            loss, bpd = model.compute_loss(batch)\n",
    "        \n",
    "        # NaN detection in loss/bpd\n",
    "        if torch.isnan(loss) or torch.isnan(bpd):\n",
    "            print(f\"âš ï¸ NaN loss detected at step {global_step}\")\n",
    "            global_step += 1\n",
    "            return {\"loss\": float(\"nan\"), \"bpd\": float(\"nan\"), \"grad_norm\": 0.0, \n",
    "                    \"lr\": scheduler.get_last_lr()[0], \"nan_detected\": True}\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "        \n",
    "        # NaN gradient detection\n",
    "        if torch.isnan(grad_norm):\n",
    "            print(f\"âš ï¸ NaN gradient at step {global_step}, skipping update\")\n",
    "            optimizer.zero_grad()\n",
    "            scaler.update()  # Must call update() to reset scaler state\n",
    "            global_step += 1\n",
    "            return {\"loss\": loss.item(), \"bpd\": bpd.item(), \"grad_norm\": float(\"nan\"),\n",
    "                    \"lr\": scheduler.get_last_lr()[0], \"nan_detected\": True}\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        loss, bpd = model.compute_loss(batch)\n",
    "        \n",
    "        # NaN detection in loss/bpd\n",
    "        if torch.isnan(loss) or torch.isnan(bpd):\n",
    "            print(f\"âš ï¸ NaN loss detected at step {global_step}\")\n",
    "            global_step += 1\n",
    "            return {\"loss\": float(\"nan\"), \"bpd\": float(\"nan\"), \"grad_norm\": 0.0,\n",
    "                    \"lr\": scheduler.get_last_lr()[0], \"nan_detected\": True}\n",
    "        \n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "        \n",
    "        # NaN gradient detection\n",
    "        if torch.isnan(grad_norm):\n",
    "            print(f\"âš ï¸ NaN gradient at step {global_step}, skipping update\")\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            return {\"loss\": loss.item(), \"bpd\": bpd.item(), \"grad_norm\": float(\"nan\"),\n",
    "                    \"lr\": scheduler.get_last_lr()[0], \"nan_detected\": True}\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    return {\n",
    "        \"loss\": loss.item(),\n",
    "        \"bpd\": bpd.item(),\n",
    "        \"grad_norm\": grad_norm.item() if isinstance(grad_norm, torch.Tensor) else grad_norm,\n",
    "        \"lr\": scheduler.get_last_lr()[0],\n",
    "        \"nan_detected\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(val_loader, num_batches=50):\n",
    "    \"\"\"Run validation on a subset of validation data.\"\"\"\n",
    "    model.eval()\n",
    "    total_bpd = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        if count >= num_batches:\n",
    "            break\n",
    "        batch = batch.to(device)\n",
    "        _, bpd = model.compute_loss(batch)\n",
    "        total_bpd += bpd.item()\n",
    "        count += 1\n",
    "    \n",
    "    return total_bpd / count if count > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "def save_checkpoint(name=None, is_best=False):\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    if name is None:\n",
    "        name = f\"checkpoint_step{global_step}.pt\"\n",
    "    \n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"global_step\": global_step,\n",
    "        \"best_bpd\": best_bpd,\n",
    "        \"train_history\": train_history,\n",
    "        \"config\": config,\n",
    "    }\n",
    "    \n",
    "    if scaler is not None:\n",
    "        checkpoint[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "    \n",
    "    torch.save(checkpoint, checkpoint_dir / name)\n",
    "    \n",
    "    if is_best:\n",
    "        torch.save(checkpoint, checkpoint_dir / \"best_model.pt\")\n",
    "\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    \"\"\"Load model checkpoint.\"\"\"\n",
    "    global global_step, best_bpd, train_history\n",
    "    \n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    global_step = checkpoint[\"global_step\"]\n",
    "    best_bpd = checkpoint[\"best_bpd\"]\n",
    "    train_history = checkpoint.get(\"train_history\", [])\n",
    "    \n",
    "    if scaler is not None and \"scaler_state_dict\" in checkpoint:\n",
    "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "    \n",
    "    print(f\"âœ“ Loaded checkpoint from step {global_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d198c97",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Run the main training loop with logging, validation, and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load from checkpoint to resume training\n",
    "# load_checkpoint(\"checkpoints/checkpoint_step10000.pt\")\n",
    "\n",
    "print(f\"Starting training from step {global_step}\")\n",
    "print(f\"Target: {config['total_steps']} steps\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Training metrics accumulators\n",
    "running_loss = 0.0\n",
    "running_bpd = 0.0\n",
    "running_count = 0\n",
    "\n",
    "# NaN tracking\n",
    "nan_count = 0\n",
    "max_consecutive_nans = 10  # Stop if this many NaNs in a row\n",
    "\n",
    "pbar = tqdm(total=config[\"total_steps\"] - global_step, desc=\"Training\")\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "while global_step < config[\"total_steps\"]:\n",
    "    # Get next batch\n",
    "    try:\n",
    "        batch = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        batch = next(train_iter)\n",
    "    \n",
    "    # Training step\n",
    "    metrics = train_step(batch)\n",
    "    \n",
    "    # Handle NaN detection\n",
    "    if metrics.get(\"nan_detected\", False):\n",
    "        nan_count += 1\n",
    "        if nan_count >= max_consecutive_nans:\n",
    "            print(f\"\\nðŸ›‘ Training stopped: {nan_count} consecutive NaNs detected!\")\n",
    "            print(\"   Try: lower learning rate, disable AMP, or check input data\")\n",
    "            break\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "    else:\n",
    "        nan_count = 0  # Reset counter on successful step\n",
    "    \n",
    "    running_loss += metrics[\"loss\"]\n",
    "    running_bpd += metrics[\"bpd\"]\n",
    "    running_count += 1\n",
    "    \n",
    "    # Logging\n",
    "    if global_step % config[\"log_interval\"] == 0:\n",
    "        avg_loss = running_loss / running_count\n",
    "        avg_bpd = running_bpd / running_count\n",
    "        \n",
    "        train_history.append({\n",
    "            \"step\": global_step,\n",
    "            \"loss\": avg_loss,\n",
    "            \"bpd\": avg_bpd,\n",
    "            \"lr\": metrics[\"lr\"],\n",
    "            \"grad_norm\": metrics[\"grad_norm\"],\n",
    "        })\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{avg_loss:.4f}\",\n",
    "            \"bpd\": f\"{avg_bpd:.3f}\",\n",
    "            \"lr\": f\"{metrics['lr']:.2e}\",\n",
    "        })\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_bpd = 0.0\n",
    "        running_count = 0\n",
    "    \n",
    "    # Validation\n",
    "    if global_step % config[\"val_interval\"] == 0:\n",
    "        val_bpd = validate(val_loader)\n",
    "        print(f\"\\n[Step {global_step}] Val BPD: {val_bpd:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_bpd < best_bpd:\n",
    "            best_bpd = val_bpd\n",
    "            save_checkpoint(is_best=True)\n",
    "            print(f\"  â†’ New best model saved! (BPD: {best_bpd:.4f})\")\n",
    "    \n",
    "    # Regular checkpointing\n",
    "    if global_step % config[\"save_interval\"] == 0:\n",
    "        save_checkpoint()\n",
    "    \n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Final save\n",
    "save_checkpoint(\"final_model.pt\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation BPD: {best_bpd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d497d4",
   "metadata": {},
   "source": [
    "## Training Visualization\n",
    "\n",
    "Plot training curves to monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de165fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "if len(train_history) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    steps = [h[\"step\"] for h in train_history]\n",
    "    bpds = [h[\"bpd\"] for h in train_history]\n",
    "    losses = [h[\"loss\"] for h in train_history]\n",
    "    lrs = [h[\"lr\"] for h in train_history]\n",
    "    grad_norms = [h[\"grad_norm\"] for h in train_history]\n",
    "    \n",
    "    # BPD curve\n",
    "    axes[0, 0].plot(steps, bpds, color=\"#e63946\", linewidth=1.5)\n",
    "    axes[0, 0].set_xlabel(\"Step\")\n",
    "    axes[0, 0].set_ylabel(\"Bits per Dimension (BPD)\")\n",
    "    axes[0, 0].set_title(\"Training BPD\")\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss curve\n",
    "    axes[0, 1].plot(steps, losses, color=\"#457b9d\", linewidth=1.5)\n",
    "    axes[0, 1].set_xlabel(\"Step\")\n",
    "    axes[0, 1].set_ylabel(\"Loss\")\n",
    "    axes[0, 1].set_title(\"Training Loss\")\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[1, 0].plot(steps, lrs, color=\"#2a9d8f\", linewidth=1.5)\n",
    "    axes[1, 0].set_xlabel(\"Step\")\n",
    "    axes[1, 0].set_ylabel(\"Learning Rate\")\n",
    "    axes[1, 0].set_title(\"Learning Rate Schedule\")\n",
    "    axes[1, 0].set_yscale(\"log\")\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gradient norm\n",
    "    axes[1, 1].plot(steps, grad_norms, color=\"#f4a261\", linewidth=1.5, alpha=0.8)\n",
    "    axes[1, 1].set_xlabel(\"Step\")\n",
    "    axes[1, 1].set_ylabel(\"Gradient Norm\")\n",
    "    axes[1, 1].set_title(\"Gradient Norm\")\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(checkpoint_dir / \"training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFinal metrics:\")\n",
    "    print(f\"  - Best BPD: {best_bpd:.4f}\")\n",
    "    print(f\"  - Final BPD: {bpds[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"No training history to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ddeda",
   "metadata": {},
   "source": [
    "## Test Compression\n",
    "\n",
    "Verify the trained model can perfectly reconstruct images (lossless compression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lossless reconstruction\n",
    "model.eval()\n",
    "\n",
    "# Get a test batch\n",
    "test_iter = iter(val_loader)\n",
    "test_batch = next(test_iter).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Compress\n",
    "    latents, prior_params = model.compress(test_batch)\n",
    "    \n",
    "    # Decompress\n",
    "    reconstructed = model.decompress(latents)\n",
    "    \n",
    "    # Check reconstruction quality\n",
    "    reconstruction_error = (test_batch - reconstructed).abs().max().item()\n",
    "    \n",
    "print(f\"Test batch shape: {test_batch.shape}\")\n",
    "print(f\"Number of latent levels: {len(latents)}\")\n",
    "print(f\"Max reconstruction error: {reconstruction_error:.6f}\")\n",
    "\n",
    "if reconstruction_error < 1.0:\n",
    "    print(\"âœ“ Perfect lossless reconstruction achieved!\")\n",
    "else:\n",
    "    print(\"âš  Reconstruction has some error (expected for flow models with rounding)\")\n",
    "\n",
    "# Visualize original vs reconstructed\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original\n",
    "    orig_img = test_batch[i].cpu().numpy().transpose(1, 2, 0) / 255.0\n",
    "    axes[0, i].imshow(np.clip(orig_img, 0, 1))\n",
    "    axes[0, i].set_title(f\"Original {i+1}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    \n",
    "    # Reconstructed\n",
    "    recon_img = reconstructed[i].cpu().numpy().transpose(1, 2, 0) / 255.0\n",
    "    axes[1, i].imshow(np.clip(recon_img, 0, 1))\n",
    "    axes[1, i].set_title(f\"Reconstructed {i+1}\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Lossless Compression Test\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
