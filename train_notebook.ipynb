{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf6a31c",
   "metadata": {},
   "source": [
    "# IDF Training Notebook\n",
    "\n",
    "Train an Integer Discrete Flow (IDF) model for lossless image compression on ImageNet-1k.\n",
    "\n",
    "This notebook uses random 64×64 crops from the streaming ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae190a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Working directory: /content/AI-Compression/AI-Compression\n",
      "Contents: ['.git', 'environment.yml', 'configs', 'README.md', 'train_notebook.ipynb', 'scripts', '.cursor', 'src', 'AI-Compression']\n",
      "⚠️  HF_TOKEN not found!\n",
      "   Create a .env file with: HF_TOKEN=your_token_here\n",
      "   Get your token at: https://huggingface.co/settings/tokens\n",
      "   Make sure you have accepted ImageNet terms at:\n",
      "   https://huggingface.co/datasets/ILSVRC/imagenet-1k\n",
      "Using device: cuda\n",
      "GPU: Tesla T4\n",
      "Memory: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COLAB SETUP - Run this cell first!\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running on Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install dependencies first\n",
    "    print('Installing dependencies...')\n",
    "    %pip install -q datasets huggingface_hub tqdm\n",
    "    \n",
    "    # Clone repo if not exists\n",
    "    if not os.path.exists('AI-Compression'):\n",
    "        !git clone https://github.com/darren10101/AI-Compression\n",
    "    os.chdir('AI-Compression')\n",
    "    \n",
    "    print(f'Working directory: {os.getcwd()}')\n",
    "    print(f'Contents: {os.listdir(\".\")}')\n",
    "    \n",
    "    # Check if src folder exists\n",
    "    if not os.path.exists('src'):\n",
    "        print('\\n⚠️  WARNING: src folder not found!')\n",
    "        print('Please clone your GitHub repo or upload the src folder.')\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da663ef8",
   "metadata": {},
   "source": [
    "## 1. Setup Dataset\n",
    "\n",
    "Create dataloaders that stream ImageNet and extract random 64×64 crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102cc18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed04136b9c9a439e8eed386e5e1fd55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HuggingFace login for ImageNet-1k access\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a31ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataloader...\n",
      "Creating validation dataloader...\n"
     ]
    }
   ],
   "source": [
    "from src.dataset.crop_dataset import create_dataloader, RandomCropDataset\n",
    "\n",
    "# Configuration\n",
    "CROP_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "# num_workers=0 is required for streaming datasets on Colab\n",
    "# (multiprocessing with IterableDataset causes issues)\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Shuffle buffer size: larger = better randomness, but slower first batch\n",
    "# - buffer_size=1: instant first batch (no shuffling)\n",
    "# - buffer_size=100: ~10-20 sec first batch, moderate shuffling\n",
    "# - buffer_size=1000: ~1-2 min first batch, good shuffling\n",
    "BUFFER_SIZE = 100  # Good tradeoff for Colab\n",
    "\n",
    "# Create dataloaders\n",
    "print('Creating training dataloader...')\n",
    "train_loader = create_dataloader(\n",
    "    split='train',\n",
    "    crop_size=CROP_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    ")\n",
    "\n",
    "print('Creating validation dataloader...')\n",
    "val_loader = create_dataloader(\n",
    "    split='validation',\n",
    "    crop_size=CROP_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b78cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading first batch (this may take a moment on first run)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0396ba00acea4ff68e8bccfb9fdf5f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead7767df5b44bf09d8757eccc3c3ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c6bf42766d4ad59fafcfe0526f4361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa174bd1f744cb3ba105d4005653637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some training samples\n",
    "# Note: First iteration may take 10-30 seconds to fill the shuffle buffer\n",
    "print('Loading first batch (this may take a moment on first run)...')\n",
    "\n",
    "# Create iterator once and reuse it\n",
    "train_iter = iter(train_loader)\n",
    "sample_batch = next(train_iter)\n",
    "\n",
    "print(f'Batch shape: {sample_batch.shape}')\n",
    "print(f'Value range: [{sample_batch.min():.1f}, {sample_batch.max():.1f}]')\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(sample_batch):\n",
    "        img = sample_batch[i].permute(1, 2, 0).numpy() / 255.0\n",
    "        ax.imshow(img.clip(0, 1))\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Sample {i+1}')\n",
    "plt.suptitle('Random 64×64 Crops from ImageNet', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75aae3",
   "metadata": {},
   "source": [
    "## 2. Create Model\n",
    "\n",
    "Initialize the Integer Discrete Flow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045e40b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 545,588\n",
      "Model config: {'in_channels': 3, 'hidden_channels': 64, 'num_levels': 3, 'num_steps': 8}\n"
     ]
    }
   ],
   "source": [
    "from src.model import create_idf_model\n",
    "\n",
    "# Model configuration\n",
    "model_config = {\n",
    "    'in_channels': 3,\n",
    "    'hidden_channels': 64,    # Width of coupling networks\n",
    "    'num_levels': 3,           # Hierarchical levels (squeeze + flow block)\n",
    "    'num_steps': 8,            # Flow steps per level\n",
    "}\n",
    "\n",
    "model = create_idf_model(model_config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameters: {num_params:,}')\n",
    "print(f'Model config: {model_config}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea77c1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1627028849.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Input shape: {test_batch.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_batch' is not defined"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "test_batch = sample_batch[:4].to(device)\n",
    "print(f'Input shape: {test_batch.shape}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss, bpd = model.compute_loss(test_batch)\n",
    "    print(f'Initial BPD: {bpd.item():.3f}')\n",
    "    print(f'(Lower is better, theoretical minimum ~4-5 bpd for natural images)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135f86e",
   "metadata": {},
   "source": [
    "## 3. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import IDFTrainer\n",
    "\n",
    "# Training configuration\n",
    "LEARNING_RATE = 1e-4\n",
    "GRAD_CLIP = 1.0\n",
    "CHECKPOINT_DIR = '../checkpoints'\n",
    "\n",
    "trainer = IDFTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    lr=LEARNING_RATE,\n",
    "    grad_clip=GRAD_CLIP,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    use_amp=True,  # Use mixed precision if available\n",
    ")\n",
    "\n",
    "print(f'Trainer initialized')\n",
    "print(f'Checkpoints will be saved to: {CHECKPOINT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954dc86c",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Run the training loop. You can interrupt at any time - checkpoints are saved periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da59c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "TOTAL_STEPS = 50000     # Adjust based on compute budget\n",
    "LOG_INTERVAL = 100      # Log every N steps\n",
    "VAL_INTERVAL = 1000     # Validate every N steps\n",
    "SAVE_INTERVAL = 5000    # Save checkpoint every N steps\n",
    "\n",
    "# Start training\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_steps=TOTAL_STEPS,\n",
    "    log_interval=LOG_INTERVAL,\n",
    "    val_interval=VAL_INTERVAL,\n",
    "    save_interval=SAVE_INTERVAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a171d0e",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "if len(history) > 0:\n",
    "    steps = [h['step'] for h in history]\n",
    "    bpds = [h['bpd'] for h in history]\n",
    "    lrs = [h['lr'] for h in history]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # BPD plot\n",
    "    axes[0].plot(steps, bpds)\n",
    "    axes[0].set_xlabel('Step')\n",
    "    axes[0].set_ylabel('Bits per Dimension (BPD)')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[1].plot(steps, lrs)\n",
    "    axes[1].set_xlabel('Step')\n",
    "    axes[1].set_ylabel('Learning Rate')\n",
    "    axes[1].set_title('Learning Rate Schedule')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Final BPD: {bpds[-1]:.4f}')\n",
    "    print(f'Best BPD: {min(bpds):.4f}')\n",
    "else:\n",
    "    print('No training history yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c03de",
   "metadata": {},
   "source": [
    "## 6. Test Compression / Reconstruction\n",
    "\n",
    "Verify the model can perfectly reconstruct images (lossless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lossless reconstruction\n",
    "model.eval()\n",
    "\n",
    "test_batch = next(iter(val_loader))[:4].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Compress\n",
    "    latents, prior_params = model.compress(test_batch)\n",
    "    \n",
    "    # Decompress\n",
    "    reconstructed = model.decompress(latents)\n",
    "    \n",
    "# Check reconstruction error\n",
    "error = (test_batch - reconstructed).abs()\n",
    "max_error = error.max().item()\n",
    "mean_error = error.mean().item()\n",
    "\n",
    "print(f'Max reconstruction error: {max_error:.6f}')\n",
    "print(f'Mean reconstruction error: {mean_error:.6f}')\n",
    "\n",
    "if max_error < 1e-4:\n",
    "    print('✓ Reconstruction is lossless!')\n",
    "else:\n",
    "    print('⚠ Reconstruction has errors (expected for untrained model)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs reconstructed\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original\n",
    "    orig = test_batch[i].cpu().permute(1, 2, 0).numpy() / 255.0\n",
    "    axes[0, i].imshow(orig.clip(0, 1))\n",
    "    axes[0, i].set_title(f'Original {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstructed\n",
    "    recon = reconstructed[i].cpu().permute(1, 2, 0).numpy() / 255.0\n",
    "    axes[1, i].imshow(recon.clip(0, 1))\n",
    "    axes[1, i].set_title(f'Reconstructed {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Lossless Compression Test', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f39bc",
   "metadata": {},
   "source": [
    "## 7. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfe5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_checkpoint('notebook_final.pt')\n",
    "print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f472968",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resume Training (Optional)\n",
    "\n",
    "To resume from a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to resume from checkpoint\n",
    "# trainer.load_checkpoint('../checkpoints/checkpoint_step10000.pt')\n",
    "# \n",
    "# # Continue training\n",
    "# history = trainer.train(\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     num_steps=100000,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
